{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File for the keyboard data analysis in the online-study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem\n",
    "plt.style.use(\"seaborn-deep\")\n",
    "\n",
    "# SK Learn imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Create custom classes for data transformation in the sklearn pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "# Imports for SK Learn RepeatedGroupKFold and Permutation Test Customizations\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection._split import check_cv\n",
    "from sklearn.base import is_classifier, clone\n",
    "from sklearn.utils import (indexable, check_random_state, _safe_indexing)\n",
    "from sklearn.metrics import check_scoring\n",
    "from sklearn.utils.metaestimators import _safe_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import the datafile ---\n",
    "dataset = pd.read_csv(\"Online_Study_Keyboard_Features.csv\", sep=\"\\t\", encoding=\"utf-8\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- get the names of all non keyboard features ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to exclude them from keyboard feature analysis\n",
    "non_keyboard_features = [\"Pr_samValence\", \"Pr_samArousal\", \"Con_samValence\", \"Con_samArousal\", \"condition\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Get the descriptive statistics about the dataset ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only get the desc stats of the keyboard features\n",
    "descriptive_hs_data = dataset.loc[dataset[\"condition\"] == 0].drop(non_keyboard_features, axis=1).describe().sort_index(axis=1)\n",
    "descriptive_ls_data = dataset.loc[dataset[\"condition\"] == 1].drop(non_keyboard_features, axis=1).describe().sort_index(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Data visualizations ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the low-stress and high-stress distribution of each variable in one plot\n",
    "for col in dataset.columns:\n",
    "    # get the high-stress and low stress data\n",
    "    hs_data = dataset.loc[dataset[\"condition\"] == 0]\n",
    "    ls_data = dataset.loc[dataset[\"condition\"] == 1]\n",
    "\n",
    "    sns.distplot(hs_data[col], hist=True, kde=True, kde_kws={\"linewidth\": 3}, label=\"HS\")\n",
    "    sns.distplot(ls_data[col], hist=True, kde=True, kde_kws={\"linewidth\": 3}, label=\"LS\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each Variable in a distplot\n",
    "for col in dataset.drop(non_keyboard_features, axis=1).columns:\n",
    "    sns.distplot(dataset[col], hist=True, kde=True, hist_kws={'edgecolor':'black'},\n",
    "                 kde_kws={\"linewidth\": 3})\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a pairplot with all relevant variables (condition phase data only)\n",
    "\n",
    "sns.pairplot(dataset.filter(regex=\"Con_\"), corner=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Plot a correlation matrix between the features\n",
    "\n",
    "# Compute the correlation matrix (for the condition phase data only)\n",
    "corr = dataset.filter(regex=\"Con_\").corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0, square=True, linewidths=.5,\n",
    "            cbar_kws={\"shrink\": .5}, annot=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- Compare each keyboard feature with a mixed ANOVA with experimental phase as the within-subject factor and condition as the between-subject factor  --\n",
    "\n",
    "#### --- ANOVA helper functions ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset for the ANOVA\n",
    "\n",
    "# helper to split the prepare the dataset for the anova and change the data from a wide to a long format\n",
    "def create_anova_df(df, variable):\n",
    "\n",
    "    anova_df = df.loc[:, [\"Con_\" + variable, \"Pr_\" + variable, \"condition\"]]\n",
    "\n",
    "    # assign a subject number to each subject\n",
    "    anova_df[\"subject\"] = np.arange(len(anova_df))\n",
    "    # replace the condition number with a string\n",
    "    anova_df[\"condition\"].replace({0: \"HS\", 1: \"LS\"}, inplace=True)\n",
    "\n",
    "    # change the format\n",
    "    anova_df = pd.melt(anova_df, id_vars=[\"subject\", \"condition\"], value_vars=[\"Pr_\" + variable, \"Con_\" + variable],\n",
    "                 var_name=\"Pr-Con\", value_name=variable)\n",
    "\n",
    "    # change the name of the column to practice and condition for clearer reading of the results\n",
    "    anova_df[\"Pr-Con\"].replace({\"Pr_\" + variable: \"Pr\", \"Con_\" + variable: \"Con\"}, inplace=True)\n",
    "\n",
    "    return anova_df\n",
    "\n",
    "\n",
    "# Create PointPlots to visualize the manipulation check results\n",
    "# Tutorial here: https://raphaelvallat.com/pingouin.html\n",
    "def plot_anova(data, variable):\n",
    "\n",
    "    # data visualization\n",
    "    sns.set()\n",
    "    sns.pointplot(data=data, x=\"Pr-Con\", y=variable, hue=\"condition\", dodge=True, markers=['o', 's'],\n",
    "                  capsize=.1, errwidth=1, palette='colorblind')\n",
    "\n",
    "    plt.title(\"Pointplot with \" + variable)\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    # save the plot\n",
    "    # plt.savefig('ANOVA' + variable + '.png')\n",
    "\n",
    "\n",
    "# calculate the anova results\n",
    "def calc_anova(data, variable):\n",
    "\n",
    "    # calculate the anova\n",
    "    aov = pg.mixed_anova(dv=variable, within=\"Pr-Con\", between=\"condition\", subject=\"subject\", data=data)\n",
    "    print(\"Repeated measures ANOVA with \" + variable)\n",
    "    pg.print_table(aov)\n",
    "    posthocs = pg.pairwise_ttests(dv=variable, within='Pr-Con', between='condition',\n",
    "                                  subject='subject', data=data, return_desc=True)\n",
    "    pg.print_table(posthocs)\n",
    "    print(\"\\n\" + \"\\n\")\n",
    "\n",
    "    # return the anova and post hoc dataframes with an added index layer that is the variable name\n",
    "    return pd.concat([aov], keys=[variable]), pd.concat([posthocs], keys=[variable])\n",
    "\n",
    "\n",
    "# helper function to get a dataframe with all anova results per task\n",
    "def get_anova_results(dataframe, variable_list):\n",
    "\n",
    "    # initialize dataframes\n",
    "    anova_df = pd.DataFrame()\n",
    "    posthoc_df = pd.DataFrame()\n",
    "\n",
    "    # loop the variable list and add the result dataframes to the initialized dataframes\n",
    "    for variable in variable_list:\n",
    "\n",
    "        anova_data = create_anova_df(dataframe, variable)\n",
    "\n",
    "        # plot the anova\n",
    "        plot_anova(anova_data, variable)\n",
    "        # calc the anova\n",
    "        anova, posthoc = calc_anova(anova_data, variable)\n",
    "\n",
    "        anova_df = pd.concat([anova_df, anova])\n",
    "        posthoc_df = pd.concat([posthoc_df, posthoc])\n",
    "\n",
    "    return anova_df, posthoc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the mixed ANOVA for each keyboard feature and save the results in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all keyboard features, which will be compared in the mixed ANOVA\n",
    "keyboard_features = [i.replace(\"Con_\", \"\") for i in dataset.columns if \"Con_\" in i and i not in non_keyboard_features]\n",
    "\n",
    "# Calculate the mixed ANOVA for each keyboard feature and save the results in one dataframe\n",
    "anova_results_df, anova_posthocs_df = get_anova_results(dataset, keyboard_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- Machine learning analysis --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Custom Helper classes for data transformation in the sk-learn pipeline ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class for custom standardization in the sk learn pipeline (only transforms the data, fit returns nothing)\n",
    "\n",
    "# select what mouse data should be used (only the condition data, the difference between the condition and baseline,\n",
    "# etc...)\n",
    "class CustomStandardization(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    \"\"\"\n",
    "    does custom transformation on the condition data by using the practice data to take individual differences into\n",
    "    account\n",
    "    1. Only use the condition trial data\n",
    "    2. use the difference score between the condition and practice trial\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method=\"ignore_practice\"):\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        # get the names of all keyboard features without a prefix\n",
    "        feat_names = [i.replace(\"Con_\", \"\") for i in X.columns if \"Con_\" in i]\n",
    "\n",
    "        if self.method == \"ignore_practice\":\n",
    "\n",
    "            # get only the names of the condition columns\n",
    "            condition_cols = [col for col in list(X.columns) if \"Con_\" in col]\n",
    "\n",
    "            return X.loc[:, condition_cols]\n",
    "\n",
    "        elif self.method == \"difference_score\":\n",
    "\n",
    "            # calculate the difference between the condition phase and baseline data\n",
    "            diff_df = pd.DataFrame()\n",
    "            for feat in feat_names:\n",
    "                diff_df[\"Diff_\" + feat] = X[\"Con_\" + feat] - X[\"Pr_\" + feat]\n",
    "\n",
    "            return diff_df\n",
    "\n",
    "        else:\n",
    "            print(\"Chosen method \" + self.method + \" does not exist. Defaulted to ignore_practice\")\n",
    "\n",
    "            condition_cols = [col for col in list(X.columns) if \"Con_\" in col]\n",
    "\n",
    "            return X.loc[:, condition_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Modified Permutation Test Score from SK Learn ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied the permutation test score function from SK Learn and adopted it so it returns the permutation test scores\n",
    "# for each fold in cross validation in order to calculate the standard deviation of the permutation test score\n",
    "\n",
    "@_deprecate_positional_args\n",
    "def permutation_test_score(estimator, X, y, *, groups=None, cv=None,\n",
    "                           n_permutations=100, n_jobs=None, random_state=0,\n",
    "                           verbose=0, scoring=None):\n",
    "    \"\"\"Evaluate the significance of a cross-validated score with permutations\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : estimator object implementing 'fit'\n",
    "        The object to use to fit the data.\n",
    "    X : array-like of shape at least 2D\n",
    "        The data to fit.\n",
    "    y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None\n",
    "        The target variable to try to predict in the case of\n",
    "        supervised learning.\n",
    "    groups : array-like of shape (n_samples,), default=None\n",
    "        Labels to constrain permutation within groups, i.e. ``y`` values\n",
    "        are permuted among samples with the same group identifier.\n",
    "        When not specified, ``y`` values are permuted among all samples.\n",
    "        When a grouped cross-validator is used, the group labels are\n",
    "        also passed on to the ``split`` method of the cross-validator. The\n",
    "        cross-validator uses them for grouping the samples  while splitting\n",
    "        the dataset into train/test set.\n",
    "    scoring : str or callable, default=None\n",
    "        A single str (see :ref:`scoring_parameter`) or a callable\n",
    "        (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
    "        If None the estimator's score method is used.\n",
    "    cv : int, cross-validation generator or an iterable, default=None\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "        - None, to use the default 5-fold cross validation,\n",
    "        - int, to specify the number of folds in a `(Stratified)KFold`,\n",
    "        - :term:`CV splitter`,\n",
    "        - An iterable yielding (train, test) splits as arrays of indices.\n",
    "        For int/None inputs, if the estimator is a classifier and ``y`` is\n",
    "        either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
    "        other cases, :class:`KFold` is used.\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validation strategies that can be used here.\n",
    "        .. versionchanged:: 0.22\n",
    "            ``cv`` default value if None changed from 3-fold to 5-fold.\n",
    "    n_permutations : int, default=100\n",
    "        Number of times to permute ``y``.\n",
    "    n_jobs : int, default=None\n",
    "        The number of CPUs to use to do the computation.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "    random_state : int, RandomState instance or None, default=0\n",
    "        Pass an int for reproducible output for permutation of\n",
    "        ``y`` values among samples. See :term:`Glossary <random_state>`.\n",
    "    verbose : int, default=0\n",
    "        The verbosity level.\n",
    "    Returns\n",
    "    -------\n",
    "    score : float\n",
    "        The true score without permuting targets.\n",
    "    permutation_scores : array of shape (n_permutations,)\n",
    "        The scores obtained for each permutations.\n",
    "    pvalue : float\n",
    "        The p-value, which approximates the probability that the score would\n",
    "        be obtained by chance. This is calculated as:\n",
    "        `(C + 1) / (n_permutations + 1)`\n",
    "        Where C is the number of permutations whose score >= the true score.\n",
    "        The best possible p-value is 1/(n_permutations + 1), the worst is 1.0.\n",
    "    Notes\n",
    "    -----\n",
    "    This function implements Test 1 in:\n",
    "        Ojala and Garriga. Permutation Tests for Studying Classifier\n",
    "        Performance.  The Journal of Machine Learning Research (2010)\n",
    "        vol. 11\n",
    "        `[pdf] <http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf>`_.\n",
    "    \"\"\"\n",
    "    X, y, groups = indexable(X, y, groups)\n",
    "\n",
    "    cv = check_cv(cv, y, classifier=is_classifier(estimator))\n",
    "    scorer = check_scoring(estimator, scoring=scoring)\n",
    "    random_state = check_random_state(random_state)\n",
    "\n",
    "    # We clone the estimator to make sure that all the folds are\n",
    "    # independent, and that it is pickle-able.\n",
    "    score = _permutation_test_score(clone(estimator), X, y, groups, cv, scorer)\n",
    "    permutation_scores = Parallel(n_jobs=n_jobs, verbose=verbose)(\n",
    "        delayed(_permutation_test_score)(\n",
    "            clone(estimator), X, _shuffle(y, groups, random_state),\n",
    "            groups, cv, scorer)\n",
    "        for _ in range(n_permutations))\n",
    "    permutation_scores = np.array(permutation_scores)\n",
    "    pvalue = (np.sum(np.mean(permutation_scores, axis=1) >= np.mean(score)) + 1.0) / (n_permutations + 1)\n",
    "    return score, permutation_scores, pvalue\n",
    "\n",
    "def _permutation_test_score(estimator, X, y, groups, cv, scorer):\n",
    "    \"\"\"Auxiliary function for permutation_test_score\"\"\"\n",
    "    avg_score = []\n",
    "    for train, test in cv.split(X, y, groups):\n",
    "        X_train, y_train = _safe_split(estimator, X, y, train)\n",
    "        X_test, y_test = _safe_split(estimator, X, y, test, train)\n",
    "        estimator.fit(X_train, y_train)\n",
    "        avg_score.append(scorer(estimator, X_test, y_test))\n",
    "    return avg_score\n",
    "\n",
    "def _shuffle(y, groups, random_state):\n",
    "    \"\"\"Return a shuffled copy of y eventually shuffle among same groups.\"\"\"\n",
    "    if groups is None:\n",
    "        indices = random_state.permutation(len(y))\n",
    "    else:\n",
    "        indices = np.arange(len(groups))\n",
    "        for group in np.unique(groups):\n",
    "            this_mask = (groups == group)\n",
    "            indices[this_mask] = random_state.permutation(indices[this_mask])\n",
    "    return _safe_indexing(y, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Helper Functions to carry out the machine learning anysis and plot the results of the permutation test ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results of the permutation procedure\n",
    "def plot_permutation_test_results(permutation_scores, model_scores, pvalue, p_tresh, method, plot_title):\n",
    "\n",
    "    # set the default colors to the seaborn color codes\n",
    "    sns.set_color_codes()\n",
    "\n",
    "    # initialize a figure with two subplots (one above the other with a 15%, 85% ratio)\n",
    "    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "\n",
    "    # plot a boxplot of the\n",
    "    sns.boxplot(model_scores, color=\"LightYellow\", showmeans=True, meanline=True,\n",
    "                meanprops={\"linestyle\": \"-\", \"linewidth\": \"3\", \"color\": \"DarkKhaki\"},\n",
    "                medianprops={\"linestyle\": \"None\", \"linewidth\": \"0\"},\n",
    "                flierprops={\"marker\": \"o\", \"markerfacecolor\": \"LightYellow\"},\n",
    "                ax=ax_box)\n",
    "\n",
    "    # set the x_label of the Boxplot to None\n",
    "    ax_box.set_xlabel(\"\")\n",
    "    # Remove the borders of the \"graph\" around the boxplot\n",
    "    ax_box.axis(\"off\")\n",
    "\n",
    "    # plot a histogram of the permutation scores\n",
    "    sns.histplot(permutation_scores, color=\"b\", bins=15, ax=ax_hist, label=\"Permutation Scores\")\n",
    "\n",
    "    # plot a vertical line of the mean cv score\n",
    "    ax_hist.axvline(np.mean(model_scores), color=\"DarkKhaki\", linewidth=3,\n",
    "                    label=\"Model Score: %.2f (%.2f), \\np = %.3f\" % (\n",
    "                    np.round(np.mean(model_scores), 3), np.round(np.std(model_scores), 3), pvalue))\n",
    "    # plot a vertical line of the mean permutation score\n",
    "    ax_hist.axvline(np.mean(permutation_scores), color=\"Navy\", linewidth=3,\n",
    "               label=\"Permutation Mean: \" \"%.2f\" % (np.round(np.mean(permutation_scores), 3)))\n",
    "    # plot a vertical line of the significance threshold\n",
    "    ax_hist.axvline(p_tresh,\n",
    "             label=\"Sig. Threshold: \" \"%.2f\" % p_tresh, color=\"darkgreen\", linestyle=\"--\", linewidth=3)\n",
    "\n",
    "    # remove the top and left corner of the\n",
    "    sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "\n",
    "    # set title\n",
    "    ax_box.set(title=plot_title)\n",
    "    # set the axis labels (depends on the score used for classification or regression)\n",
    "    if method == \"Classification\":\n",
    "        score_label = \"Accuracy Score\"\n",
    "    else:\n",
    "        score_label = \"RÂ² Score\"\n",
    "    plt.xlabel(score_label)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    # loc legend to the top left\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(plot_title + \".png\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# calculates a k-fold cross val score and compares the mean performance score with a distribution of n models that\n",
    "# were trained with permutated class labels\n",
    "# more information can be found here:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html\n",
    "def ml_permutation_test(iv, dv, algorithm, method, standard_method, cv_repeats, permutation_repeats, procedure_title):\n",
    "\n",
    "    # save the results of the permutation test\n",
    "    results = {}\n",
    "\n",
    "    # initiate the pipeline and select the desired configurations for handling multicollinearity and\n",
    "    # the feature selection procedure\n",
    "    # make a pipeline that does the preprocessing and outputs the cross validation score\n",
    "    pipeline = Pipeline([\n",
    "        (\"custom_transformation\", CustomStandardization(method=standard_method)),\n",
    "        (\"standardization\", StandardScaler()),\n",
    "        (\"clf\", algorithm)\n",
    "    ])\n",
    "\n",
    "    # initialize the repeated k-fold iterator (use stratified k-fold cv to get approximately equal group sizes during\n",
    "    # each fold)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=cv_repeats)\n",
    "\n",
    "    # get the scoring function\n",
    "    if method == \"Classification\":\n",
    "        scorer = \"accuracy\"\n",
    "    else:\n",
    "        scorer = \"r2\"\n",
    "\n",
    "    # get the cross validation scores the permuation scores and the p-value of the permutation test\n",
    "    scores, permutation_scores, pvalue = permutation_test_score(pipeline, iv, dv, scoring=scorer,\n",
    "                                                                cv=cv, n_permutations=permutation_repeats)\n",
    "\n",
    "    # get the statistical values of the model scores\n",
    "    model_score = np.mean(scores)\n",
    "    model_std = np.std(scores)\n",
    "    model_std_err = sem(scores)\n",
    "\n",
    "    # get the statistical values of the permutation (in repeated cv, its n_splits * n_repeats scores for each\n",
    "    # permutation run --> num of permutation_scores = n_splits * n_repeats scores * n_permutations)\n",
    "    perm_score = np.mean(permutation_scores)\n",
    "    perm_std = np.std(np.mean(permutation_scores, axis=1))\n",
    "    # Get the significance threshold (the classification model must be better than 95% of the permutated models)\n",
    "    sig_tresh = np.percentile(np.mean(permutation_scores, axis=1), 95.0)\n",
    "\n",
    "    # save the results\n",
    "    results[\"Mean_score\"] = np.round(model_score, 4)\n",
    "    results[\"SD_score\"] = np.round(model_std, 4)\n",
    "    results[\"SE_score\"] = np.round(model_std_err, 4)\n",
    "    results[\"p_value\"] = np.round(pvalue, 5)\n",
    "    results[\"Mean_Permutation_score\"] = np.round(perm_score, 4)\n",
    "    results[\"Std_Permutation_score\"] = np.round(perm_std, 4)\n",
    "    results[\"Sig_Treshold\"] = sig_tresh\n",
    "\n",
    "    plot_permutation_test_results(permutation_scores=np.mean(permutation_scores, axis=1),\n",
    "                                  model_scores=scores,\n",
    "                                  pvalue=np.round(pvalue, 3),\n",
    "                                  p_tresh=np.round(sig_tresh, 3),\n",
    "                                  method=method,\n",
    "                                  plot_title=procedure_title)\n",
    "\n",
    "    # output the results and scores\n",
    "    return results, scores\n",
    "\n",
    "\n",
    "# helper function for repeated k-fold cross validation without a permutation test\n",
    "def rep_kfold_cv(iv, dv, algorithm, method, standard_method, cv_repeats):\n",
    "\n",
    "    # save the results of the permutation test\n",
    "    results = {}\n",
    "\n",
    "    # initiate the pipeline and select the desired configurations for handling multicollinearity and\n",
    "    # the feature selection procedure\n",
    "    # make a pipeline that does the preprocessing and outputs the cross validation score\n",
    "    pipeline = Pipeline([\n",
    "        (\"custom_transformation\", CustomStandardization(method=standard_method)),\n",
    "        (\"standardization\", StandardScaler()),\n",
    "        (\"clf\", algorithm)\n",
    "    ])\n",
    "\n",
    "    # initialize the repeated k-fold iterator with non-overlapping groups\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=cv_repeats)\n",
    "\n",
    "    # get the scoring function\n",
    "    if method == \"Classification\":\n",
    "        scorer = \"accuracy\"\n",
    "    else:\n",
    "        scorer = \"r2\"\n",
    "\n",
    "    # get the scores of repeated 5-fold cross validation\n",
    "    scores = cross_val_score(pipeline, X=iv, y=dv, scoring=scorer, cv=cv)\n",
    "    print(scores)\n",
    "\n",
    "    # calculate and save the results\n",
    "    results[\"Mean_score\"] = np.round(np.mean(scores), 2)\n",
    "    results[\"SD_score\"] = np.round(np.std(scores), 2)\n",
    "    results[\"SE_score\"] = np.round(sem(scores), 2)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Helper function to run the machine learning analysis with all relevant settings for classification and regression with the raw data and difference score data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the permutation test with the \"final settings\" and save the results in a pandas dataframe\n",
    "def get_ML_results(data, method, diff_score_method, permutation_test, dv):\n",
    "\n",
    "    permutation_results = {}\n",
    "\n",
    "    # dict with different algorithms for classification/regression\n",
    "    algorithms = {\n",
    "        \"Classification\": {\n",
    "            \"kNN_class\": KNeighborsClassifier(n_neighbors=3)},\n",
    "        \"Regression\": {\n",
    "            \"RidgeReg\": RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])},\n",
    "    }\n",
    "\n",
    "    # get the dependent and independent variable of the machine learning analysis\n",
    "    predictors = data.drop(non_keyboard_features, axis=1)\n",
    "\n",
    "    if method == \"Regression\":\n",
    "        if diff_score_method == \"difference_score\":\n",
    "            dependent_variable = data[\"Con_\" + dv] - data[\"Pr_\" + dv]\n",
    "        else:\n",
    "            dependent_variable = data[\"Con_\" + dv]\n",
    "    else:\n",
    "        dependent_variable = data[dv]\n",
    "\n",
    "    # perform the permuation test with all algorithms\n",
    "    for alg in algorithms[method]:\n",
    "        if permutation_test:\n",
    "            analysis_title = method + \" Permutation test with target \" + dv + \" using \" + alg + \" and \" + diff_score_method\n",
    "            print(analysis_title)\n",
    "            # get the results of the permutation test\n",
    "            result_dic, model_scores = ml_permutation_test(iv=predictors,\n",
    "                                                           dv=dependent_variable,\n",
    "                                                           algorithm=algorithms[method][alg],\n",
    "                                                           method=method,\n",
    "                                                           standard_method=diff_score_method,\n",
    "                                                           cv_repeats=5,\n",
    "                                                           permutation_repeats=1000,\n",
    "                                                           procedure_title=analysis_title)\n",
    "        else:\n",
    "            analysis_title = method + \" repeated cv with target \" + dv + \" using \" + alg + \" and \" + diff_score_method\n",
    "            print(analysis_title)\n",
    "            result_dic = rep_kfold_cv(iv=predictors,\n",
    "                                      dv=dependent_variable,\n",
    "                                      algorithm=algorithms[method][alg],\n",
    "                                      method=method,\n",
    "                                      standard_method=diff_score_method,\n",
    "                                      cv_repeats=5)\n",
    "            print(result_dic)\n",
    "\n",
    "        # save the results with labeled index in the results dictionary\n",
    "        permutation_results[(method, dv, alg)] = result_dic\n",
    "        break\n",
    "\n",
    "    # create a multiindexed dataframe from the results dictionary\n",
    "    permutation_results_df = pd.DataFrame(permutation_results).T\n",
    "\n",
    "    return permutation_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Run the Machine Learning Analysis---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_classification_results = get_ML_results(dataset, method=\"Classification\",\n",
    "                                             diff_score_method=\"ignore_practice\", dv=\"condition\",\n",
    "                                             permutation_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression on Valence and Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valence\n",
    "valence_regression_results = get_ML_results(dataset, method=\"Regression\",\n",
    "                                            diff_score_method=\"ignore_practice\", dv=\"samValence\",\n",
    "                                            permutation_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arousal\n",
    "arousal_regression_results = get_ML_results(dataset, method=\"Regression\", diff_score_method=\"ignore_practice\",\n",
    "                                            dv=\"samArousal\", permutation_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the Difference score data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the same analysis using the difference score between the condition phase and practice phase to account for\n",
    "# individual differences in typing behavior\n",
    "diff_cond_classification_results = get_ML_results(dataset, method=\"Classification\",\n",
    "                                                  diff_score_method=\"difference_score\", dv=\"condition\",\n",
    "                                                  permutation_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression on Valence and Arousal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valence\n",
    "diff_valence_regression_results = get_ML_results(dataset, method=\"Regression\",\n",
    "                                                 diff_score_method=\"difference_score\", dv=\"samValence\",\n",
    "                                                 permutation_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arousal\n",
    "diff_arousal_regression_results = get_ML_results(dataset, method=\"Regression\",\n",
    "                                                 diff_score_method=\"difference_score\",\n",
    "                                                 dv=\"samArousal\", permutation_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- merge all machine learning results together into one dataframe ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition classification\n",
    "ml_classification_results = pd.concat([pd.concat([cond_classification_results], keys=[\"Raw_data\"]),\n",
    "                        pd.concat([diff_cond_classification_results], keys=[\"Diff_data\"])])\n",
    "# regression\n",
    "ml_reg1 = pd.concat([pd.concat([valence_regression_results, arousal_regression_results])], keys=[\"Raw_data\"])\n",
    "ml_reg2 = pd.concat([pd.concat([diff_valence_regression_results, diff_arousal_regression_results])], keys=[\"Diff_data\"])\n",
    "\n",
    "ml_regression_results = pd.concat([ml_reg1, ml_reg2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -- Save the results of all keyboard feature analysis (mixed ANOVA, ML & des. stats) in one excel file --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results in one excel file\n",
    "# save the dataframe plus the descriptive stats as an excel file\n",
    "with pd.ExcelWriter(\"Online_Study_Keyboard_Feature_Analysis.xlsx\") as writer:\n",
    "    # save the descriptive stats\n",
    "    descriptive_hs_data.to_excel(writer, float_format=\"%.3f\", sheet_name=\"Descriptive Stats High-Stress\")\n",
    "    descriptive_ls_data.to_excel(writer, float_format=\"%.3f\", sheet_name=\"Descriptive Stats Low-Stress\")\n",
    "    # save the anova results\n",
    "    anova_results_df.to_excel(writer, float_format=\"%.4f\", sheet_name=\"Mixed Anova Results\")\n",
    "    anova_posthocs_df.to_excel(writer, float_format=\"%.4f\", sheet_name=\"Anova Posthocs Result\")\n",
    "    # save the machine learning classification results\n",
    "    ml_classification_results.to_excel(writer, float_format=\"%.4f\", sheet_name=\"Machine_Learning_Classification\")\n",
    "    # save the machine learning regression results\n",
    "    ml_regression_results.to_excel(writer, float_format=\"%.4f\", sheet_name=\"Machine_Learning_Regression\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:full_conda]",
   "language": "python",
   "name": "conda-env-full_conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
