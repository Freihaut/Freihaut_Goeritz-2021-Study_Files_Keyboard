{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File for the manipulation check in the online-study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "# \"Extra package\"\n",
    "import pingouin as pg\n",
    "# Vallat, R. (2018). Pingouin: statistics in Python. Journal of Open Source Software, 3(31), 1026,\n",
    "# https://doi.org/10.21105/joss.01026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "with open(\"OnlineStudy_RawData.json\") as jsonData:\n",
    "    dataset = json.load(jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the ids after removing bad cases in the typing task\n",
    "with open(\"filtered_online_study_ids_taskLvl\", \"rb\") as fp:\n",
    "    filter_task_lvl = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the sociodemographic dataset\n",
    "sociodem_df = pd.read_csv(\"OnlineStudy_sociodemographic_data.csv\", index_col=\"firebase_id\")\n",
    "sociodem_df = sociodem_df.loc[filter_task_lvl, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- create a dataframe with the data for the manipulation check ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manipulation_check_data = {}\n",
    "\n",
    "# loop over all datasets\n",
    "for par in dataset:\n",
    "\n",
    "    # only include the data of the selected participants\n",
    "    if par in filter_task_lvl:\n",
    "\n",
    "        manipulation_check_data[par] = {}\n",
    "\n",
    "        # MDBF\n",
    "\n",
    "        # recode some items of the MDBF scale\n",
    "        items_to_recode = [\"MDBF_angespannt\", \"MDBF_nervoes\", \"MDBF_schlaefrig\", \"MDBF_ungluecklich\",\n",
    "                           \"MDBF_unzufrieden\", \"MDBF_ermattet\"]\n",
    "\n",
    "        # get the data for the practice and actual condition\n",
    "\n",
    "        # Condition\n",
    "        for item in dataset[par][\"Con_Mdbf\"][\"data\"]:\n",
    "            value = dataset[par][\"Con_Mdbf\"][\"data\"][item]\n",
    "            if item in items_to_recode:\n",
    "                manipulation_check_data[par][\"Con_\" + item] = 4 - value\n",
    "            else:\n",
    "                manipulation_check_data[par][\"Con_\" + item] = value\n",
    "\n",
    "        # Practice\n",
    "        for item in dataset[par][\"Pr_Mdbf\"][\"data\"]:\n",
    "            value = dataset[par][\"Pr_Mdbf\"][\"data\"][item]\n",
    "            if item in items_to_recode:\n",
    "                manipulation_check_data[par][\"Pr_\" + item] = 4 - value\n",
    "            else:\n",
    "                manipulation_check_data[par][\"Pr_\" + item] = value\n",
    "\n",
    "        # SAM\n",
    "\n",
    "        for page in dataset[par]:\n",
    "            if \"_Sam_\" in page:\n",
    "                manipulation_check_data[par][page + \"_Valenz\"] = dataset[par][page][\"data\"][\"samValence\"]\n",
    "                manipulation_check_data[par][page + \"_Arousal\"] = dataset[par][page][\"data\"][\"samArousal\"]\n",
    "\n",
    "        # Count Task Answers\n",
    "\n",
    "        count_answer = 0\n",
    "        count_targets = 0\n",
    "        for page in dataset[par]:\n",
    "            if \"_Count_\" in page:\n",
    "                targs = dataset[par][page][\"data\"][\"Total_num_targets\"]\n",
    "                manipulation_check_data[par][\"count_targets_\" + page[9:]] = targs\n",
    "                count_targets += targs\n",
    "            if \"_CountAns_\" in page:\n",
    "                ans = dataset[par][page][\"data\"][\"Count_Task_Answer\"]\n",
    "                manipulation_check_data[par][\"count_answer_\" + page[12:]] = ans\n",
    "                count_answer += ans\n",
    "\n",
    "        manipulation_check_data[par][\"Count_Total_Ans\"] = count_answer\n",
    "        manipulation_check_data[par][\"Count_Total_Targets\"] = count_targets\n",
    "\n",
    "        # Add the condition to the Dataset\n",
    "        manipulation_check_data[par][\"condition\"] = dataset[par][\"ExperimentMetaData\"][\"condition\"]\n",
    "\n",
    "# create a pandas dataframe with the manipulation check data\n",
    "man_check_df = pd.DataFrame(manipulation_check_data).T\n",
    "\n",
    "# create the MDBF scales\n",
    "man_check_df[\"Con_MDBF_GS\"] = (man_check_df[\"Con_MDBF_wohl\"] + man_check_df[\"Con_MDBF_gut\"] + man_check_df[\n",
    "    \"Con_MDBF_ungluecklich\"] + man_check_df[\"Con_MDBF_unzufrieden\"]) / 4\n",
    "man_check_df[\"Con_MDBF_RU\"] = (man_check_df[\"Con_MDBF_ausgeglichen\"] + man_check_df[\"Con_MDBF_ruhig\"] + man_check_df[\n",
    "    \"Con_MDBF_angespannt\"] + man_check_df[\"Con_MDBF_nervoes\"]) / 4\n",
    "man_check_df[\"Con_MDBF_WM\"] = (man_check_df[\"Con_MDBF_frisch\"] + man_check_df[\"Con_MDBF_wach\"] + man_check_df[\n",
    "    \"Con_MDBF_schlaefrig\"] + man_check_df[\"Con_MDBF_ermattet\"]) / 4\n",
    "\n",
    "man_check_df[\"Pr_MDBF_GS\"] = (man_check_df[\"Pr_MDBF_wohl\"] + man_check_df[\"Pr_MDBF_gut\"] + man_check_df[\n",
    "    \"Pr_MDBF_ungluecklich\"] + man_check_df[\"Pr_MDBF_unzufrieden\"]) / 4\n",
    "man_check_df[\"Pr_MDBF_RU\"] = (man_check_df[\"Pr_MDBF_ausgeglichen\"] + man_check_df[\"Pr_MDBF_ruhig\"] + man_check_df[\n",
    "    \"Pr_MDBF_angespannt\"] + man_check_df[\"Pr_MDBF_nervoes\"]) / 4\n",
    "man_check_df[\"Pr_MDBF_WM\"] = (man_check_df[\"Pr_MDBF_frisch\"] + man_check_df[\"Pr_MDBF_wach\"] + man_check_df[\n",
    "    \"Pr_MDBF_schlaefrig\"] + man_check_df[\"Pr_MDBF_ermattet\"]) / 4\n",
    "\n",
    "# merge all SAM items together to one\n",
    "man_check_df[\"Con_valence_merged\"] = (man_check_df['Con_Sam_PatternTyping_Valenz'] + man_check_df['Con_Sam_DragDrop_Valenz'] +\n",
    "                                      man_check_df['Con_Sam_FollowBox_Valenz'] + man_check_df['Con_Sam_PointClick_Valenz'] +\n",
    "                                      man_check_df['Con_Sam_Slider_Valenz']) / 5\n",
    "\n",
    "man_check_df[\"Con_arousal_merged\"] = (man_check_df['Con_Sam_PatternTyping_Arousal'] + man_check_df['Con_Sam_DragDrop_Arousal'] +\n",
    "                                      man_check_df['Con_Sam_FollowBox_Arousal'] + man_check_df['Con_Sam_PointClick_Arousal'] +\n",
    "                                      man_check_df['Con_Sam_Slider_Arousal']) / 5\n",
    "\n",
    "man_check_df[\"Pr_valence_merged\"] = (man_check_df['Pr_Sam_PatternTyping_Valenz'] + man_check_df['Pr_Sam_DragDrop_Valenz'] +\n",
    "                                      man_check_df['Pr_Sam_FollowBox_Valenz'] + man_check_df['Pr_Sam_PointClick_Valenz'] +\n",
    "                                      man_check_df['Pr_Sam_Slider_Valenz']) / 5\n",
    "\n",
    "man_check_df[\"Pr_arousal_merged\"] = (man_check_df['Pr_Sam_PatternTyping_Arousal'] + man_check_df['Pr_Sam_DragDrop_Arousal'] +\n",
    "                                      man_check_df['Pr_Sam_FollowBox_Arousal'] + man_check_df['Pr_Sam_PointClick_Arousal'] +\n",
    "                                      man_check_df['Pr_Sam_Slider_Arousal']) / 5\n",
    "\n",
    "\n",
    "# concat the sociodemographic info the the manipultation check dataframe\n",
    "man_check_df = pd.concat([man_check_df, sociodem_df], axis=1)\n",
    "\n",
    "# list all manipulation check items\n",
    "list(man_check_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " count the number of participants per condition\n",
    "# 0 = high stress, 1 = low stress\n",
    "print(\"Number of participants per condition:\", \"\\n\", man_check_df[\"condition\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Get a list of all variables which are included in the manipulation check ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to test\n",
    "\n",
    "mdbf = [\"MDBF_GS\", \"MDBF_RU\", \"MDBF_WM\", \"stress\", \"nostalgia\"]\n",
    "sam = ['Sam_PatternTyping_Arousal',\n",
    "       'Sam_PatternTyping_Valenz',\n",
    "       'arousal_merged',\n",
    "       'valence_merged',\n",
    "       'Sam_DragDrop_Arousal',\n",
    "       'Sam_DragDrop_Valenz',\n",
    "       'Sam_FollowBox_Arousal',\n",
    "       'Sam_FollowBox_Valenz',\n",
    "       'Sam_PointClick_Arousal',\n",
    "       'Sam_PointClick_Valenz',\n",
    "       'Sam_Slider_Arousal',\n",
    "       'Sam_Slider_Valenz', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Get the descriptive stats of the manipulation check data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get descriptive statistics of SAM, Count Answers, MDBF answers\n",
    "descriptive_hs_data = man_check_df.loc[man_check_df[\"condition\"] == 0].drop([\"Con_MDBF_wohl\", \"Con_MDBF_gut\",\n",
    "                                                                             \"Con_MDBF_ungluecklich\", \"Con_MDBF_unzufrieden\",\n",
    "                                                                             \"Con_MDBF_ausgeglichen\", \"Con_MDBF_ruhig\", \"Con_MDBF_angespannt\", \"Con_MDBF_nervoes\",\n",
    "                                                                             \"Con_MDBF_frisch\", \"Con_MDBF_wach\", \"Con_MDBF_schlaefrig\", \"Con_MDBF_ermattet\",\n",
    "                                                                             \"Pr_MDBF_wohl\", \"Pr_MDBF_gut\", \"Pr_MDBF_ungluecklich\", \"Pr_MDBF_unzufrieden\",\n",
    "                                                                             \"Pr_MDBF_ausgeglichen\", \"Pr_MDBF_ruhig\", \"Pr_MDBF_angespannt\", \"Pr_MDBF_nervoes\",\n",
    "                                                                             \"Pr_MDBF_frisch\", \"Pr_MDBF_wach\", \"Pr_MDBF_schlaefrig\", \"Pr_MDBF_ermattet\"\n",
    "                                                                             ], axis=1).describe().sort_index(axis=1)\n",
    "descriptive_ls_data = man_check_df.loc[man_check_df[\"condition\"] == 1].drop([\"Con_MDBF_wohl\", \"Con_MDBF_gut\", \"Con_MDBF_ungluecklich\", \"Con_MDBF_unzufrieden\",\n",
    "                                                                             \"Con_MDBF_ausgeglichen\", \"Con_MDBF_ruhig\", \"Con_MDBF_angespannt\", \"Con_MDBF_nervoes\",\n",
    "                                                                             \"Con_MDBF_frisch\", \"Con_MDBF_wach\", \"Con_MDBF_schlaefrig\", \"Con_MDBF_ermattet\",\n",
    "                                                                             \"Pr_MDBF_wohl\", \"Pr_MDBF_gut\", \"Pr_MDBF_ungluecklich\", \"Pr_MDBF_unzufrieden\",\n",
    "                                                                             \"Pr_MDBF_ausgeglichen\", \"Pr_MDBF_ruhig\", \"Pr_MDBF_angespannt\", \"Pr_MDBF_nervoes\",\n",
    "                                                                             \"Pr_MDBF_frisch\", \"Pr_MDBF_wach\", \"Pr_MDBF_schlaefrig\", \"Pr_MDBF_ermattet\"\n",
    "                                                                             ], axis=1).describe().sort_index(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Calculate Cronbachs alpha for the MDBF subscales ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cronbachs_alphas = {}\n",
    "\n",
    "# get the Cronbach's Alpha Values of the MDBF scale\n",
    "mdbf_scales = {\n",
    "    \"Con_GS\": [\"Con_MDBF_wohl\", \"Con_MDBF_gut\", \"Con_MDBF_ungluecklich\", \"Con_MDBF_unzufrieden\"],\n",
    "    \"Con_RU\": [\"Con_MDBF_ausgeglichen\", \"Con_MDBF_ruhig\", \"Con_MDBF_angespannt\", \"Con_MDBF_nervoes\"],\n",
    "    \"Con_WM\": [\"Con_MDBF_frisch\", \"Con_MDBF_wach\", \"Con_MDBF_schlaefrig\", \"Con_MDBF_ermattet\"],\n",
    "    \"Pr_GS\": [\"Pr_MDBF_wohl\", \"Pr_MDBF_gut\", \"Pr_MDBF_ungluecklich\", \"Pr_MDBF_unzufrieden\"],\n",
    "    \"Pr_RU\": [\"Pr_MDBF_ausgeglichen\", \"Pr_MDBF_ruhig\", \"Pr_MDBF_angespannt\", \"Pr_MDBF_nervoes\"],\n",
    "    \"Pr_WM\": [\"Pr_MDBF_frisch\", \"Pr_MDBF_wach\", \"Pr_MDBF_schlaefrig\", \"Pr_MDBF_ermattet\"]\n",
    "}\n",
    "\n",
    "# show and save the cronbachs alpha values per MDBF scale\n",
    "for i in mdbf_scales:\n",
    "    cronbachs_alphas[i] = {}\n",
    "    # get cronbachs alpha for the high-stress and low-stress condition separately\n",
    "    alpha_hs = pg.cronbach_alpha(data=man_check_df.loc[man_check_df[\"condition\"] == 0].loc[:, mdbf_scales[i]])\n",
    "    alpha_ls = pg.cronbach_alpha(data=man_check_df.loc[man_check_df[\"condition\"] == 1].loc[:, mdbf_scales[i]])\n",
    "    print(\"Cronbachs Alpha HS condition\" + str(i), alpha_hs)\n",
    "    print(\"Cronbachs Alpha LS condition\" + str(i), alpha_ls)\n",
    "    cronbachs_alphas[i][\"HS_alpha\"] = alpha_hs[0]\n",
    "    cronbachs_alphas[i][\"HS_alpha_ci\"] = alpha_hs[1]\n",
    "    cronbachs_alphas[i][\"LS_alpha\"] = alpha_ls[0]\n",
    "    cronbachs_alphas[i][\"LS_alpha_ci\"] = alpha_ls[1]\n",
    "\n",
    "# save the cronbach alphas as a dataframe\n",
    "cronbachs_alphas_df = pd.DataFrame(cronbachs_alphas).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Main Manipulation Check analysis using a mixed ANOVA with experimental phase as within-subject factor and condition as between subject factor ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- helper functions to do the mixed ANOVA ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset for the ANOVA\n",
    "\n",
    "# helper to split the prepare the dataset for the anova and change the data from a wide to a long format\n",
    "def create_anova_df(data, variable):\n",
    "    # assign a subject number to each subject\n",
    "    data[\"subject\"] = np.arange(len(data))\n",
    "    # replace the condition number with a string\n",
    "    data[\"condition\"].replace({0: \"HS\", 1: \"LS\"}, inplace=True)\n",
    "\n",
    "    # change the format from wide to long\n",
    "    df = pd.melt(data, id_vars=[\"subject\", \"condition\"], value_vars=[\"Pr_\" + variable, \"Con_\" + variable],\n",
    "                 var_name=\"Pr-Con\", value_name=variable)\n",
    "\n",
    "    # change the name of the column to practice and condition for clearer reading of the results\n",
    "    df[\"Pr-Con\"].replace({\"Pr_\" + variable: \"Pr\", \"Con_\" + variable: \"Con\"}, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PointPlots to visualize the manipulation check results\n",
    "# Tutorial here: https://raphaelvallat.com/pingouin.html\n",
    "def plot_anova(data, variable):\n",
    "\n",
    "    dataset = create_anova_df(data, variable)\n",
    "    # data visualization\n",
    "    sns.set()\n",
    "    sns.pointplot(data=dataset, x=\"Pr-Con\", y=variable, hue=\"condition\", dodge=True, markers=['o', 's'],\n",
    "                  capsize=.1, errwidth=1, palette='colorblind')\n",
    "\n",
    "    plt.title(\"Pointplot with \" + variable)\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    # save the plot\n",
    "    # plt.savefig('ANOVA' + variable + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the anova results\n",
    "\n",
    "def calc_anova(data, variable):\n",
    "\n",
    "    # get the dataset\n",
    "    dataset = create_anova_df(data, variable)\n",
    "    # data visualization\n",
    "    aov = pg.mixed_anova(dv=variable, within=\"Pr-Con\", between=\"condition\", subject=\"subject\", data=dataset)\n",
    "    print(\"Repeated measures ANOVA with \" + variable)\n",
    "    pg.print_table(aov)\n",
    "    posthocs = pg.pairwise_ttests(dv=variable, within='Pr-Con', between='condition',\n",
    "                                  subject='subject', data=dataset, return_desc=True)\n",
    "    pg.print_table(posthocs)\n",
    "    print(\"\\n\" + \"\\n\")\n",
    "\n",
    "    # return the anova and post hoc dataframes with an added index layer that is the variable name\n",
    "    return pd.concat([aov], keys=[variable]), pd.concat([posthocs], keys=[variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to calc the result dataframes from a variables list\n",
    "def get_anova_results(data, variable_list):\n",
    "\n",
    "    # initialize dataframes\n",
    "    anova_df = pd.DataFrame()\n",
    "    posthoc_df = pd.DataFrame()\n",
    "\n",
    "    # loop the variable list and add the result dataframes to the initialized dataframes\n",
    "    for i in variable_list:\n",
    "\n",
    "        anova, posthoc = calc_anova(data, i)\n",
    "\n",
    "        anova_df = pd.concat([anova_df, anova])\n",
    "        posthoc_df = pd.concat([posthoc_df, posthoc])\n",
    "\n",
    "    return anova_df, posthoc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Do the ANOVA analysis (speratelty for the MDBF subscales and for the SAM) ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. plot the anova graphs for the mdbf (use the entire sample)\n",
    "for i in mdbf:\n",
    "    plot_anova(man_check_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. get the manipulation check anova results for the MDBF\n",
    "mdbf_anova, mdbf_posthocs = get_anova_results(man_check_df, mdbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. plot the anova graphs for the sam (use the entire sample)\n",
    "for i in sam:\n",
    "    plot_anova(man_check_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. get the anova results for the sam\n",
    "sam_anova, sam_posthocs = get_anova_results(man_check_df, sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- Save the results of all calculations in the manipulation check in one excel file ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "# save the anova and post hoc results in an excel file\n",
    "with pd.ExcelWriter(\"Online_Study_Manipulation_Check_Results.xlsx\") as writer:\n",
    "    descriptive_hs_data.to_excel(writer, sheet_name=\"Des_Stats_High_Stress_Condition\")\n",
    "    descriptive_ls_data.to_excel(writer, sheet_name=\"Des_Stats_Low_Stress_Condition\")\n",
    "    mdbf_anova.to_excel(writer, sheet_name=\"MDBF_Anova\")\n",
    "    mdbf_posthocs.to_excel(writer, sheet_name=\"MDBF_Posthocs\")\n",
    "    sam_anova.to_excel(writer, sheet_name=\"SAM_Anova\")\n",
    "    sam_posthocs.to_excel(writer, sheet_name=\"SAM_Posthocs\")\n",
    "    cronbachs_alphas_df.to_excel(writer, sheet_name=\"Cronbachs_Alphas\")\n",
    "\n",
    "print(\"Successfully saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:full_conda]",
   "language": "python",
   "name": "conda-env-full_conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
